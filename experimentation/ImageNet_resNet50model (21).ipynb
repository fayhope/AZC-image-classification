{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dytINVMFy0M"
   },
   "source": [
    "# Test Training with ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mCN7RItw0lzk",
    "outputId": "c8e5f9f1-f579-42b5-baab-d8162ef3f24e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm  # for progress bar\n",
    "from IPython.display import display, Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a file from a URL with a custom progress bar\n",
    "def download_file(url, save_path):\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        progress = tqdm(total=total_size, unit='B', unit_scale=True, desc=os.path.basename(save_path), ncols=80)\n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    progress.update(len(chunk))\n",
    "        progress.close()\n",
    "        \n",
    "\n",
    "# URLs for ImageNet dataset files (replace with actual download links)\n",
    "train_url = 'http://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar'\n",
    "val_url = 'http://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar'\n",
    "\n",
    "# Directory to save dataset files\n",
    "dataset_dir = '/home/ec2-user/SageMaker/imagenet_dataset'\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Download train dataset\n",
    "train_tar_path = os.path.join(dataset_dir, 'ILSVRC2012_img_train.tar')\n",
    "print(f\"Downloading train dataset from {train_url}...\")\n",
    "download_file(train_url, train_tar_path)\n",
    "\n",
    "\n",
    "\n",
    "# Download validation dataset\n",
    "val_tar_path = os.path.join(dataset_dir, 'ILSVRC2012_img_val.tar')\n",
    "print(f\"Downloading validation dataset from {val_url}...\")\n",
    "download_file(val_url, val_tar_path)\n",
    "\n",
    "\n",
    "# Extract train dataset\n",
    "print(f\"Extracting train dataset to {dataset_dir}...\")\n",
    "with tarfile.open(train_tar_path, 'r') as tar:\n",
    "    tar.extractall(dataset_dir)\n",
    "\n",
    "    \n",
    "# Extract validation dataset\n",
    "print(f\"Extracting validation dataset to {dataset_dir}...\")\n",
    "with tarfile.open(val_tar_path, 'r') as tar:\n",
    "    tar.extractall(dataset_dir)\n",
    "\n",
    "print(\"Dataset extraction complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "////////////////////////////////////////////////////////////////////////////////////////////////\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 22:03:36.379601: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-07 22:03:36.379874: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-07 22:03:38.237233: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-07 22:03:41.052812: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-07 22:03:54.433476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed in 55.10 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Define the target synset IDs and their corresponding animal names\n",
    "target_species_synsets = {\n",
    "    'n02129165': 'lion',\n",
    "    'n02129604': 'tiger',\n",
    "    'n02391049': 'zebra',\n",
    "    'n02504013': 'elephant',\n",
    "    'n02398521': 'hippo',\n",
    "    'n02138441': 'meerkat',\n",
    "    'n02480855': 'gorilla',\n",
    "    'n02056570': 'king_penguin',\n",
    "    'n02130308': 'cheetah',\n",
    "    'n02509815': 'red_panda',\n",
    "    'n02133161': 'black_bear',\n",
    "    'n02497673': 'lemur',\n",
    "    'n02007558': 'flamingo',\n",
    "    'n02481823': 'chimpanzee',\n",
    "    'n02480495': 'orangutan',\n",
    "    'n02128925': 'jaguar',\n",
    "    'n02510455': 'panda',\n",
    "    'n02454379': 'armadillo',\n",
    "    'n02117135': 'hyena',\n",
    "    'n01644373': 'tree_frog'\n",
    "}\n",
    "\n",
    "def extract_images_to_folders(dataset_dir, output_dir, target_synsets, max_images_per_synset=1300, train_size=1000):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create training and validation directories\n",
    "    train_dir = os.path.join(output_dir, 'training')\n",
    "    val_dir = os.path.join(output_dir, 'validation')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_extracted = 0\n",
    "    \n",
    "    for synset_id, animal_name in target_synsets.items():\n",
    "        synset_tar_path = os.path.join(dataset_dir, f\"{synset_id}.tar\")\n",
    "        \n",
    "        # Create class output directories in both training and validation\n",
    "        train_class_output_dir = os.path.join(train_dir, f\"{synset_id}_{animal_name}\")\n",
    "        val_class_output_dir = os.path.join(val_dir, f\"{synset_id}_{animal_name}\")\n",
    "        os.makedirs(train_class_output_dir, exist_ok=True)\n",
    "        os.makedirs(val_class_output_dir, exist_ok=True)\n",
    "        \n",
    "        with tarfile.open(synset_tar_path, 'r') as tar:\n",
    "            members = [m for m in tar.getmembers() if m.isfile()]\n",
    "            members = members[:max_images_per_synset]\n",
    "            \n",
    "            for idx, member in enumerate(members):\n",
    "                if idx < train_size:\n",
    "                    # Copy to training directory\n",
    "                    tar.extract(member, path=train_class_output_dir)\n",
    "                else:\n",
    "                    # Copy to validation directory\n",
    "                    tar.extract(member, path=val_class_output_dir)\n",
    "                \n",
    "                total_extracted += 1\n",
    "                \n",
    "                if total_extracted >= len(target_synsets) * max_images_per_synset:\n",
    "                    break\n",
    "            \n",
    "            if total_extracted >= len(target_synsets) * max_images_per_synset:\n",
    "                break\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Extraction completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Define the dataset directory and the output directory\n",
    "dataset_dir = '/home/ec2-user/SageMaker/imagenet_dataset'  \n",
    "output_dir = '/home/ec2-user/SageMaker/imagenet_extracted'\n",
    "\n",
    "# Extract images for target synsets, aiming for 1000 in training and 300 in validation per synset ID\n",
    "extract_images_to_folders(dataset_dir, output_dir, target_species_synsets, max_images_per_synset=1300, train_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "////////////////////////////////////////////////////////////////////////////////////////////////\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 20 classes.\n",
      "Found 6000 files belonging to 20 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 2s 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 22:10:23.375134: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 27591300 exceeds 10% of free system memory.\n",
      "2024-07-07 22:10:23.689285: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2024-07-07 22:10:23.711774: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 20313600 exceeds 10% of free system memory.\n",
      "2024-07-07 22:10:23.735464: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2024-07-07 22:10:23.829363: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 19267584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3735s 6s/step - loss: 2.8792 - accuracy: 0.1144 - val_loss: 2.7652 - val_accuracy: 0.1790\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3778s 6s/step - loss: 2.7352 - accuracy: 0.1767 - val_loss: 2.6951 - val_accuracy: 0.1857\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3704s 6s/step - loss: 2.6583 - accuracy: 0.2074 - val_loss: 2.6443 - val_accuracy: 0.1927\n",
      "Epoch 4/10\n",
      "172/625 [=======>......................] - ETA: 33:08 - loss: 2.6031 - accuracy: 0.2269"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "# Assuming img_height, img_width, and batch_size are defined\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Assuming class_names are defined\n",
    "class_names = ['lion', 'tiger', 'zebra', 'elephant', 'hippo', 'meerkat', \n",
    "               'gorilla', 'king_penguin', 'cheetah', 'red_panda', \n",
    "               'black_bear', 'lemur', 'flamingo', 'chimpanzee', \n",
    "               'orangutan', 'jaguar', 'panda', 'armadillo', 'hyena', 'tree_frog']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Check available GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Define data directories\n",
    "train_dir = '/home/ec2-user/SageMaker/imagenet_extracted/training'\n",
    "val_dir = '/home/ec2-user/SageMaker/imagenet_extracted/validation'\n",
    "\n",
    "# Load datasets\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "# Normalize datasets\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Load ResNet50 pretrained model without top layers\n",
    "resnet50_model = tf.keras.applications.ResNet50(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "resnet50_model.trainable = False\n",
    "\n",
    "# Create the model\n",
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "x = resnet50_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(num_classes)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1  # Set verbose to 1 for detailed progress bar\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming history contains the training history returned by model.fit()\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QjN0kZhsyi10",
    "-zH9H1Bxej7M",
    "-e6sBdPL5kGF",
    "pzeJSN51hjwg",
    "1gocKHWFhpid",
    "vLEBryOdhtG8",
    "kc45dBqH59U-",
    "NdetEw4-h1gt",
    "rMZYFONYjLe7",
    "piQJcxKL7qiV",
    "iZOa5NdsjWfy",
    "MysCimySj1Mn",
    "okGZP1Ni3-er"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
