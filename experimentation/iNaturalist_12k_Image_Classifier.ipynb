{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "Converting a university Assignment in Jupyter Notebook on how to use CNNs into a Google Colab notebook.\n",
        "\n",
        "The aim is to train a image classification model on the [Inaturalist 12K Dataset](https://storage.googleapis.com/wandb_datasets/nature_12K.zip).\n",
        "\n",
        "The dataset features:  \n",
        "\n",
        "*   10 classes\n",
        "*   10k images\n",
        "\n",
        "The dataset will be split into 90% training and 10% for validation.\n",
        "\n",
        "The original assignment utilised wandb for experimental tracking and reporting on the model during it's training and testing phase. However, I have removed the code as I do not have access to a wandb API key.\n",
        "\n",
        "Original Repo:\n",
        "https://github.com/PranjalChitale/CS6910_Assignment2/tree/main\n",
        "\n"
      ],
      "metadata": {
        "id": "1o9c9uBjVPd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "Importing the required libraries."
      ],
      "metadata": {
        "id": "saPNob9aYAjb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwKk84eLUyQa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import different pretrained image-classification models.\n",
        "https://keras.io/api/applications/"
      ],
      "metadata": {
        "id": "VjMN1L8ZYIpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n"
      ],
      "metadata": {
        "id": "mPyxKU-LXurR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifying the tensorflow version is latest 2.15.0\n"
      ],
      "metadata": {
        "id": "lQxmdSNdYVEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opIi1mvzYXg9",
        "outputId": "876b7240-f484-4f07-cf3f-82d34cf78dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the Dataset\n"
      ],
      "metadata": {
        "id": "OPAFidx5YerT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the inaturalist dataset."
      ],
      "metadata": {
        "id": "z_FB1OyKYlwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "dataset_dir = tf.keras.utils.get_file(\"nature_12K\",origin=dataset_url,cache_dir='.',extract=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw_Cu2UxYp9X",
        "outputId": "0e1cae31-88b0-4187-efcf-0cc6a77868d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "3816687935/3816687935 [==============================] - 42s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n"
      ],
      "metadata": {
        "id": "tXOb1ATwZTAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Directories\n",
        "Setting the train dataset and test dataset directory."
      ],
      "metadata": {
        "id": "6O0LGsA1ZZFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset_dir = './datasets/inaturalist_12K/train/'\n",
        "testset_dir = './datasets/inaturalist_12K/val/'\n",
        "classlist = [name for name in os.listdir(trainset_dir) if os.path.isdir(os.path.join(trainset_dir, name))]"
      ],
      "metadata": {
        "id": "rwcGvKYdZR1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the train dataset and val dataset\n"
      ],
      "metadata": {
        "id": "WTLKOdP7a1dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_train_val(path, augmentation, batch_size, image_size):\n",
        "    rescaledata = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
        "    #Splits the dataset into train and validation.\n",
        "    #Keras' ImageDataGenerator is used to split data into train and test.\n",
        "    if augmentation:\n",
        "        #Applies data augmentation if specified\n",
        "        train_data_gen = ImageDataGenerator(\n",
        "                            rescale = 1./255,\n",
        "                            horizontal_flip = True,\n",
        "                            rotation_range = 30,\n",
        "                            shear_range = 0.2,\n",
        "                            zoom_range = 0.2,\n",
        "                            width_shift_range = 0.2,\n",
        "                            height_shift_range = 0.2,\n",
        "                            validation_split = 0.1,\n",
        "                        )\n",
        "    else:\n",
        "        train_data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.10)\n",
        "\n",
        "    \"\"\"\n",
        "    Flow from directory expects that images belonging to each class is present in its own folder\n",
        "    but inside the same parent folder : data directory. It takes path to the data directory as\n",
        "    input and generates batches of desired batch size. Need to specify appropriate subset\n",
        "    (training / validation) to generate batches for respective subset.\n",
        "    \"\"\"\n",
        "\n",
        "    train_data = train_data_gen.flow_from_directory(\n",
        "            path,\n",
        "            target_size=image_size,\n",
        "            color_mode=\"rgb\",\n",
        "            batch_size=batch_size,\n",
        "            class_mode=\"sparse\",\n",
        "            shuffle=True,\n",
        "            seed = 0,\n",
        "            subset=\"training\"\n",
        "        )\n",
        "\n",
        "    val_data = train_data_gen.flow_from_directory(\n",
        "        path,\n",
        "        target_size=image_size,\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"sparse\",\n",
        "        shuffle=True,\n",
        "        seed=0,\n",
        "        subset=\"validation\"\n",
        "    )\n",
        "\n",
        "    #Gets the list of class labels.\n",
        "    class_labels = list(train_data.class_indices.keys())\n",
        "\n",
        "\n",
        "    return train_data, val_data, class_labels"
      ],
      "metadata": {
        "id": "Jp9i6Ftba8Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the test dataset"
      ],
      "metadata": {
        "id": "-ILc0LS1cVpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_test(path, batch_size, image_size):\n",
        "    #Generates batches of test data.\n",
        "    test_data_gen = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        "    )\n",
        "\n",
        "    test_data = test_data_gen.flow_from_directory(\n",
        "            path,\n",
        "            target_size=image_size,\n",
        "            color_mode=\"rgb\",\n",
        "            batch_size=batch_size,\n",
        "            class_mode=\"sparse\",\n",
        "            shuffle=True,\n",
        "            seed=0,\n",
        "        )\n",
        "\n",
        "    return test_data"
      ],
      "metadata": {
        "id": "Fu01iDLVcYPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "This includes training predicting and logging the experiments.\n",
        "\n"
      ],
      "metadata": {
        "id": "zxEjtl7Zcl18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config = None ):\n",
        "\n",
        "    # Reading and setting the configuation\n",
        "    batch_size = config['batch_size']\n",
        "    augmentation = config['augmentation']\n",
        "    pretrain_model = config['pretrain_model']\n",
        "    droprate = config['droprate']\n",
        "    batch_norm = config['batch_normalization']\n",
        "    epoch = config['epoch']\n",
        "    fc_size = config[\"fc_size\"]\n",
        "    num_of_trainable_layers = config['num_of_trainable_layers']\n",
        "\n",
        "    # Choosing the pretrained model based on configuration input.\n",
        "    if pretrain_model == 'InceptionV3':\n",
        "        image_size = (299,299)\n",
        "        base_model = tf.keras.applications.InceptionV3(include_top = False,weights='imagenet', input_shape=image_size+(3,))\n",
        "\n",
        "    elif pretrain_model == 'InceptionResNetV2':\n",
        "        image_size = (299,299)\n",
        "        base_model = tf.keras.applications.InceptionResNetV2(include_top = False,weights='imagenet',input_shape=image_size+(3,))\n",
        "\n",
        "    elif pretrain_model == 'ResNet50':\n",
        "        image_size = (224,224)\n",
        "        base_model = tf.keras.applications.ResNet50(include_top = False,weights='imagenet',input_shape=image_size+(3,))\n",
        "\n",
        "    elif pretrain_model == 'Xception':\n",
        "        image_size = (299,299)\n",
        "        base_model = tf.keras.applications.Xception(include_top = False,weights='imagenet',input_shape=image_size+(3,))\n",
        "\n",
        "    elif pretrain_model == 'MobileNetV2':\n",
        "        image_size = (224,224)\n",
        "        base_model = tf.keras.applications.MobileNetV2(include_top = False,weights='imagenet',input_shape=image_size+(3,))\n",
        "\n",
        "    # Freezing the pretrained model's layer.\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Adding the new fully connected layer on top of the feature extraction layers of pretrained model.\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=image_size+(3,)),\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dense(fc_size,activation='relu'),\n",
        "    ])\n",
        "\n",
        "    if batch_norm:\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dropout(droprate))\n",
        "    model.add(Dense(fc_size, activation='relu'))\n",
        "    model.add(Dropout(droprate))\n",
        "    train_data,val_data,class_labels = generate_batch_train_val(trainset_dir, augmentation, batch_size,image_size)\n",
        "    model.add(Dense(len(class_labels) ,activation='softmax'))\n",
        "\n",
        "    # Setting the optimisation and loss function.\n",
        "    model.compile(\n",
        "        optimizer= 'adam',\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Dividing the epoch between pretraining and fine-tuning(if asked).\n",
        "    if num_of_trainable_layers > 0:\n",
        "        fine_tuning_epoch = int(epoch/2)\n",
        "        pretrain_epoch = int(epoch/2)\n",
        "    else:\n",
        "        pretrain_epoch = epoch\n",
        "\n",
        "    # Training the model.\n",
        "    hist=model.fit(train_data,epochs=pretrain_epoch,validation_data=val_data)#,callbacks=[wandb_callback]\n",
        "\n",
        "\n",
        "    # Fine-tuning\n",
        "    # Based on input, if number of trainable layers are >0, then setting that number of the freezed layers in pretrained model trainable.\n",
        "    if num_of_trainable_layers > 0:\n",
        "        num_of_trainable_layers=num_of_trainable_layers+(len(model.layers)-len(base_model.layers))\n",
        "        for layer in reversed(model.layers):\n",
        "            if(num_of_trainable_layers> 0):\n",
        "                layer.trainable=True\n",
        "                num_of_trainable_layers -= 1\n",
        "\n",
        "        model.compile(\n",
        "            optimizer= tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Fine tuning.\n",
        "        hist=model.fit(train_data,epochs=fine_tuning_epoch,validation_data=val_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "ewCcMbnjcwk-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running\n",
        "### Best parameters configuration run."
      ],
      "metadata": {
        "id": "MKJ8i-Aid3ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'pretrain_model': 'Xception',\n",
        "    'epoch':9,\n",
        "    'batch_size': 16,\n",
        "    'augmentation': True,\n",
        "    'fc_size': 256,\n",
        "    'droprate':0.4,\n",
        "    'batch_normalization': True,\n",
        "    'num_of_trainable_layers' : 1\n",
        "    }\n",
        "train(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "L1DK6U6Rd017",
        "outputId": "07ad6964-03b9-40b6-807c-67928f25d4d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n",
            "Found 9000 images belonging to 10 classes.\n",
            "Found 999 images belonging to 10 classes.\n",
            "Epoch 1/4\n",
            "154/563 [=======>......................] - ETA: 47:46 - loss: 1.6310 - accuracy: 0.4841"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-51ac3e8617c0>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m'num_of_trainable_layers'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     }\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-2295ac6521fa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Training the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrain_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,callbacks=[wandb_callback]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sweep configuration"
      ],
      "metadata": {
        "id": "eFVfIfqnd-zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'name': 'A2_B_bayes',\n",
        "    'method': 'bayes',\n",
        "    'early_terminate':{'type': 'hyperband', 'min_iter': 3},\n",
        "    'metric':{'name':'val_Accuracy','goal':'maximize'},\n",
        "    'parameters': {\n",
        "        'pretrain_model' : {'values' :['InceptionV3','InceptionResNetV2','ResNet50','Xception','MobileNetV2']},\n",
        "        'epoch' : {'values':[6,9]},\n",
        "        'batch_size' : {'values':[16,32,128]},\n",
        "        'augmentation':{'values':[True,False]},\n",
        "        'fc_size': {'values': [128,256,512]},\n",
        "        'droprate':{'values': [0.4,0.5]},\n",
        "        'batch_normalization': {'values':[True,False]},\n",
        "        'num_of_trainable_layers' : {'values': [0,1,2]},\n",
        "\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "OWdOdaKMeEW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}